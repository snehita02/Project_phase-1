{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4e9354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "from keras.models import load_model\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras_preprocessing.image import img_to_array   \n",
    "\n",
    "from keras import losses \n",
    "from keras import optimizers \n",
    "from keras import metrics \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "from keras.models import load_model\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras_preprocessing.image import img_to_array\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "from numpy import expand_dims\n",
    "from keras.models import load_model\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras_preprocessing.image import img_to_array\n",
    "\n",
    "\n",
    "from PIL import Image, ImageFont, ImageDraw \n",
    "import cv2\n",
    "import pyttsx3 as p \n",
    "from threading import Thread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da8d7453",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoundBox:\n",
    "\tdef __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
    "\t\tself.xmin = xmin\n",
    "\t\tself.ymin = ymin\n",
    "\t\tself.xmax = xmax\n",
    "\t\tself.ymax = ymax\n",
    "\t\tself.objness = objness\n",
    "\t\tself.classes = classes\n",
    "\t\tself.label = -1\n",
    "\t\tself.score = -1\n",
    "\n",
    "\tdef get_label(self):\n",
    "\t\tif self.label == -1:\n",
    "\t\t\tself.label = np.argmax(self.classes)\n",
    "\n",
    "\t\treturn self.label\n",
    "\n",
    "\tdef get_score(self):\n",
    "\t\tif self.score == -1:\n",
    "\t\t\tself.score = self.classes[self.get_label()]\n",
    "\t\treturn self.score\n",
    "    \n",
    "def _sigmoid(x):\n",
    "\treturn 1. / (1. + np.exp(-x))\n",
    "    \n",
    "    \n",
    "\n",
    "def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n",
    "\tgrid_h, grid_w = netout.shape[:2] \n",
    "\tnb_box = 3 \n",
    "\tnetout = netout.reshape((grid_h, grid_w, nb_box, -1)) \n",
    "\tnb_class = netout.shape[-1] - 5\n",
    "\tboxes = []\n",
    "\tnetout[..., :2]  = _sigmoid(netout[..., :2])\n",
    "\tnetout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
    "\tnetout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
    "\tnetout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
    "\tfor i in range(grid_h*grid_w):\n",
    "\t\trow = i / grid_w\n",
    "\t\tcol = i % grid_w\n",
    "\t\tfor b in range(nb_box):\n",
    "\t\t\tobjectness = netout[int(row)][int(col)][b][4]\n",
    "\t\t\tif(objectness.all() <= obj_thresh): continue\n",
    "\t\t\tx, y, w, h = netout[int(row)][int(col)][b][:4]\n",
    "\t\t\tx = (col + x) / grid_w \n",
    "\t\t\ty = (row + y) / grid_h \n",
    "\t\t\tw = anchors[2 * b + 0] * np.exp(w) / net_w \n",
    "\t\t\th = anchors[2 * b + 1] * np.exp(h) / net_h \n",
    "\t\t\tclasses = netout[int(row)][col][b][5:]\n",
    "\t\t\tbox = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
    "\t\t\tboxes.append(box)\n",
    "\treturn boxes    \n",
    "\n",
    "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
    "\tnew_w, new_h = net_w, net_h\n",
    "\tfor i in range(len(boxes)):\n",
    "\t\tx_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
    "\t\ty_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
    "\t\tboxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
    "\t\tboxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
    "\t\tboxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
    "\t\tboxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
    "    \n",
    "    \n",
    "\n",
    "def _interval_overlap(interval_a, interval_b):\n",
    "\tx1, x2 = interval_a\n",
    "\tx3, x4 = interval_b\n",
    "\tif x3 < x1:\n",
    "\t\tif x4 < x1:\n",
    "\t\t\treturn 0\n",
    "\t\telse:\n",
    "\t\t\treturn min(x2,x4) - x1\n",
    "\telse:\n",
    "\t\tif x2 < x3:\n",
    "\t\t\t return 0\n",
    "\t\telse:\n",
    "\t\t\treturn min(x2,x4) - x3 \n",
    "\n",
    "\n",
    "def bbox_iou(box1, box2):\n",
    "\tintersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "\tintersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
    "\tintersect = intersect_w * intersect_h\n",
    "    \n",
    "    \n",
    "\tw1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin  \n",
    "\tw2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "\tunion = w1*h1 + w2*h2 - intersect\n",
    "\treturn float(intersect) / union\n",
    "\n",
    "def do_nms(boxes, nms_thresh):   \n",
    "\tif len(boxes) > 0:\n",
    "\t\tnb_class = len(boxes[0].classes)\n",
    "\telse:\n",
    "\t\treturn\n",
    "\tfor c in range(nb_class):\n",
    "\t\tsorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
    "\t\tfor i in range(len(sorted_indices)):\n",
    "\t\t\tindex_i = sorted_indices[i]\n",
    "\t\t\tif boxes[index_i].classes[c] == 0: continue\n",
    "\t\t\tfor j in range(i+1, len(sorted_indices)):\n",
    "\t\t\t\tindex_j = sorted_indices[j]\n",
    "\t\t\t\tif bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
    "\t\t\t\t\tboxes[index_j].classes[c] = 0 \n",
    "    \n",
    "\n",
    "# load and prepare an image\n",
    "def load_image_pixels(filename, shape):\n",
    "\timage = load_img(filename)\n",
    "\twidth, height = image.size\n",
    "\timage = load_img(filename, target_size=shape) \n",
    "\timage = img_to_array(image)\n",
    "\timage = image.astype('float32')\n",
    "\timage /= 255.0 \n",
    "\timage = expand_dims(image, 0)\n",
    "\treturn image, width, height\n",
    "    \n",
    "    \n",
    "\n",
    "def get_boxes(boxes, labels, thresh):\n",
    "\tv_boxes, v_labels, v_scores = list(), list(), list()\n",
    "\tfor box in boxes:\n",
    "\t\tfor i in range(len(labels)):\n",
    "\t\t\tif box.classes[i] > thresh:\n",
    "\t\t\t\tv_boxes.append(box)\n",
    "\t\t\t\tv_labels.append(labels[i])\n",
    "\t\t\t\tv_scores.append(box.classes[i]*100)\n",
    "\treturn v_boxes, v_labels, v_scores \n",
    "    \n",
    "    \n",
    "\n",
    "# -------------------------------------------- distance of object  ---------------------------------------------- \n",
    "\n",
    "def dis(real_width,ref_width,width):\n",
    "    known_dis = 45 \n",
    "    focal_length = (known_dis * real_width ) / ref_width\n",
    "    distance = (focal_length * real_width ) / width\n",
    "    return distance   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------- voice output ---------------------------------------------- \n",
    "\n",
    "def speak(txt):\n",
    "    speak = p.init()\n",
    "    speak.say(txt)\n",
    "    speak.runAndWait()  \n",
    "\n",
    "def talk(view):\n",
    "    for k,v in view.items():\n",
    "        if len(v) != 0:\n",
    "            for k1,v1 in v.items():\n",
    "                if k == 'front':\n",
    "                    if len(v1) == 1: \n",
    "                        txt = 'one ' + k1 + ' are in ' + k + ' of you ' + str(min(v1)) + ' meters'\n",
    "                        speak(txt)  \n",
    "                    else:\n",
    "                        txt = str(len(v1)) + ' ' + k1 + 's are in ' + k + ' of you '  + str(min(v1)) + ' meters'\n",
    "                        speak(txt) \n",
    "                else:\n",
    "                    if len(v1) == 1: \n",
    "                        txt = 'one ' + k1 + ' is in ' + k + ' side'+ ' from you '  + str(min(v1)) + ' meters'\n",
    "                        speak(txt)\n",
    "                    else:\n",
    "                        txt = str(len(v1)) + ' ' + k1 + 's are in ' + k  + ' side'+ ' from you '  + str(min(v1)) + ' meters'\n",
    "                        speak(txt) \n",
    "\n",
    "\n",
    "# --------------------------------------- direction dictionary ------------------------------------------\n",
    "\n",
    "def check(x,y,w,view,display,label,real_width,ref_width):\n",
    "    mid_point = x + w // 2\n",
    "    if (x + w) < display['left'][1] :\n",
    "        if label not in view['left'].keys(): \n",
    "            view['left'][label] = [] \n",
    "        view['left'][label].append(round(dis(real_width[label],ref_width[label],w)*10,2)) \n",
    "        return \n",
    "    if x > display['right'][0]:  \n",
    "        if label not in view['right'].keys(): \n",
    "            view['right'][label] = []\n",
    "        view['right'][label].append(round(dis(real_width[label],ref_width[label],w)*10,2))\n",
    "        return \n",
    "    for k,v in display.items():\n",
    "        if v[0] <= mid_point and mid_point <= v[1]:\n",
    "            if label not in view[k].keys(): \n",
    "                view[k][label] = []\n",
    "            view[k][label].append(round(dis(real_width[label],ref_width[label],w)*10,2))\n",
    "            return \n",
    "    if mid_point < display['left'][0]:\n",
    "        if label not in view['left'].keys(): \n",
    "            view['left'][label] = []\n",
    "        view['left'][label].append(round(dis(real_width[label],ref_width[label],w)*10,2))\n",
    "        return \n",
    "    if label not in view['right'].keys(): \n",
    "        view['right'][label] = []\n",
    "    view['right'][label].append(round(dis(real_width[label],ref_width[label],w)*10,2)) \n",
    "    return \n",
    "    \n",
    "\n",
    "\n",
    "# --------------------------------------- distance estimation varaibles ---------------------------------------\n",
    "\n",
    "p2 = ''\n",
    "\n",
    "real_width = {\"person\" : 16, \"bicycle\" : 66, \"car\" : 109, \"motorbike\" : 57, \"aeroplane\" : 590, \"bus\": 472 , \"train\": 529 , \"truck\" : 496,\n",
    "        \"boat\": 120 , \"traffic light\" : 11, \"fire hydrant\": 12  , \"stop sign\" : 20 , \"parking meter\": 177 , \"bench\":48 ,\n",
    "        \"bird\":9 , \"cat\":15 , \"dog\":25 , \"horse\": 35 , \"sheep\": 27 , \"cow\": 35 , \"elephant\": 145 , \"bear\": 96, \"zebra\":96 , \"giraffe\":192 ,\n",
    "        \"backpack\":12 , \"umbrella\":51 , \"handbag\":9 , \"tie\": 3 , \"suitcase\":20 , \"frisbee\":3937  , \"skis\":70 , \"snowboard\":63 ,\n",
    "        \"sports ball\":9 , \"kite\":9 , \"baseball bat\":34 , \"baseball glove\":13 , \"skateboard\":9 , \"surfboard\":77 ,\n",
    "        \"tennis racket\":27 , \"bottle\":3 , \"wine glass\":3 , \"cup\":4 , \"fork\":6 , \"knife\":8 , \"spoon\":6 , \"bowl\":5 , \"banana\":6 ,\n",
    "        \"apple\":3 , \"sandwich\":4 , \"orange\":3 , \"broccoli\":4 , \"carrot\":5 , \"hot dog\":6 , \"pizza\":8 , \"donut\":5 , \"cake\":10 ,\n",
    "        \"chair\":17 , \"sofa\":77 , \"pottedplant\":9 , \"bed\":85 , \"diningtable\":50 , \"toilet\":16 , \"tvmonitor\":32 , \"laptop\":15 , \"mouse\":4 ,\n",
    "        \"remote\":6 , \"keyboard\":15 , \"cell phone\":5 , \"microwave\":14 , \"oven\":17 , \"toaster\":8 , \"sink\":19 , \"refrigerator\":23 ,\n",
    "        \"book\":11 , \"clock\":12 , \"vase\":9 , \"scissors\":7 , \"teddy bear\":15 , \"hair drier\":12 , \"toothbrush\":7 }  \n",
    "\n",
    "ref_width =   {'person': 179, 'bicycle': 387, 'car': 334, 'motorbike': 395, 'aeroplane': 296, 'bus': 283, 'train': 290, 'truck': 329, 'boat': 230,\n",
    "           'traffic light': 349, 'fire hydrant': 389, 'stop sign': 191, 'parking meter': 382, 'bench': 342, 'bird': 315, 'cat': 341\n",
    "           , 'dog': 242, 'horse': 386, 'sheep': 377, 'cow': 339, 'elephant': 329, 'bear': 270, 'zebra': 385,\n",
    "           'giraffe': 211, 'backpack': 335, 'umbrella': 387, 'handbag': 285, 'tie': 374, \n",
    "           'suitcase': 170, 'frisbee': 303, 'skis': 174, 'snowboard': 128, 'sports ball': 361, 'kite': 338, 'baseball bat': 300,\n",
    "           'baseball glove': 160, 'skateboard': 378, 'surfboard': 229, 'tennis racket': 417, 'bottle': 70, 'wine glass': 256,\n",
    "           'cup': 255, 'fork': 315, 'knife': 395, 'spoon': 379, 'bowl': 376, 'banana': 356, 'apple': 272, 'sandwich': 322,\n",
    "           'orange': 295, 'broccoli': 261, 'carrot': 243, 'hot dog': 379, 'pizza': 388, 'donut': 342, 'cake': 378, \n",
    "           'chair': 258, 'sofa': 336, 'pottedplant': 407, 'bed': 394, 'diningtable': 350, 'toilet': 292, \n",
    "           'tvmonitor': 375, 'laptop': 378, 'mouse': 275, 'remote': 434, 'keyboard': 180, 'cell phone': 256, \n",
    "           'microwave': 367, 'oven': 417, 'toaster': 136, 'sink': 120, 'refrigerator': 257, 'book': 462, \n",
    "           'clock': 299, 'vase': 157, 'scissors': 379, 'teddy bear': 273, 'hair drier': 109, 'toothbrush': 412}\n",
    "\n",
    "\n",
    "# --------------------------------------- drawing rectangle in cv2 ---------------------------------------\n",
    "    \n",
    "def cvdraw(photo_filename, v_boxes, v_labels, v_scores):\n",
    "    img=cv2.imread(photo_filename) \n",
    "    direction = ''\n",
    "    height,width,channels = img.shape\n",
    "    image_size = width\n",
    "    ratio = '1:2:1'\n",
    "    ratio_list = list(map(int,ratio.split(':'))) \n",
    "    parts = sum(ratio_list)\n",
    "    one_part = image_size // parts \n",
    "    l = ratio_list[0] * one_part \n",
    "    f = ratio_list[1] * one_part \n",
    "    r =  ratio_list[2] * one_part  \n",
    "    display = {\n",
    "    'left'  : [0 , l],\n",
    "    'front' : [l + 1 , f + l] , \n",
    "    'right' : [f + l + 1 , image_size] \n",
    "    } \n",
    "    view = {\n",
    "        'left' :dict(),\n",
    "        'front':dict(),\n",
    "        'right':dict()\n",
    "    }\n",
    "    count = 0 \n",
    "    op = []\n",
    "    for i in range(len(v_boxes)):\n",
    "        count += 1 \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        org = (50, 50)\n",
    "        fontScale = 0.4\n",
    "        color = (0, 0, 0) \n",
    "        thickness = 1\n",
    "        x = v_boxes[i].xmin \n",
    "        y = v_boxes[i].ymin\n",
    "        w = v_boxes[i].xmax\n",
    "        h = v_boxes[i].ymax  \n",
    "        op.append([x,y,w])\n",
    "        \n",
    "        check(x,y,w,view,display,v_labels[i],real_width,ref_width)  \n",
    "        \n",
    "        confi = str(round(v_scores[i],2)/100) \n",
    "        confi = confi[0:4]\n",
    "        text_size, _ = cv2.getTextSize(v_labels[i] + '  ' +confi, font, fontScale,thickness)\n",
    "        text_w, text_h = text_size\n",
    "        cv2.rectangle(img, (x,y) , (x + text_w + 5, y - text_h - 5), (0,255,0) , -1)\n",
    "        cv2.rectangle(img, (x, y), (w, h),color=(0, 255, 0), thickness=2)\n",
    "        cv2.putText(img, v_labels[i] + '  ' +confi,(x+2,y-2), font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "    for k,v in view.items():\n",
    "        for k1,v1 in v.items():\n",
    "            print(k,k1,v1)\n",
    "    print(\"total detections : \",count) \n",
    "    print(op)   \n",
    "#     print('width : ',w)\n",
    "    cv2.imshow('img',img)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows() \n",
    "#     talk(view) \n",
    "    if len(view) != 0:\n",
    "        p2 = Thread(target = talk , args = (view,))\n",
    "        p2.start()\n",
    "    else:\n",
    "        talk('You can walk freely now') \n",
    "#     if cv2.waitKey(48) == ord('q'):\n",
    "#     cv2.waitKey(0)   \n",
    "#     cv2.destroyAllWindows() \n",
    "#     return w \n",
    "\n",
    "# --------------------------------------- drawing rectangle in pillow --------------------------------------- \n",
    "# def cvdraw(photo_filename, v_boxes, v_labels, v_scores):\n",
    "#     image = Image.open(photo_filename)\n",
    "#     for i in range(len(v_boxes)):\n",
    "#         x = v_boxes[i].xmin\n",
    "#         y = v_boxes[i].ymin\n",
    "#         w = v_boxes[i].xmax\n",
    "#         h = v_boxes[i].ymax \n",
    "#         draw = ImageDraw.Draw(image) \n",
    "#         left = (x,y)\n",
    "#         right = (w,h) \n",
    "#         position = (x+3,y+3)\n",
    "#         text = v_labels[i] + '  ' +str(round(v_scores[i],2) )\n",
    "#         bbox = draw.textbbox(position, text ) \n",
    "#         draw.rectangle(bbox, fill=(0,255,0))\n",
    "#         draw.text(position, text,  fill=\"black\") \n",
    "#         draw.rectangle((left,right),outline=(0,255,0),width=3) \n",
    "#     image.show()\n",
    "#     image.close() \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397624e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3594d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "model = load_model('model.h5')\n",
    "model.compile(loss = 'mean_squared_error',optimizer = 'sgd', metrics = [metrics.categorical_accuracy]) \n",
    "def image_detection(photo_filename): \n",
    "#     photo_filename = cv2.resize(photo_filename,(416,416))\n",
    "    input_w, input_h = 416, 416   \n",
    "    input_w, input_h = 416, 416 \n",
    "    image, image_w, image_h = load_image_pixels(photo_filename, (input_w, input_h))\n",
    "    yhat = model.predict(image) \n",
    "    anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]  \n",
    "    class_threshold = 0.6\n",
    "    boxes = list()\n",
    "    for i in range(len(yhat)):\n",
    "        boxes += decode_netout(yhat[i][0], anchors[i], class_threshold, input_h, input_w)\n",
    "    correct_yolo_boxes(boxes, image_h, image_w, input_h, input_w)\n",
    "    do_nms(boxes, 0.5)   \n",
    "    labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\",\n",
    "        \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\n",
    "        \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\",\n",
    "        \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\",\n",
    "        \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\",\n",
    "        \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\",\n",
    "        \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
    "        \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\",\n",
    "        \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\",\n",
    "        \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]  \n",
    "    v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n",
    "    cvdraw(photo_filename, v_boxes, v_labels, v_scores)          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "438fe22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "total detections :  0\n",
      "[]\n",
      "1/1 [==============================] - 0s 427ms/step\n",
      "total detections :  0\n",
      "[]\n",
      "1/1 [==============================] - 0s 428ms/step\n",
      "front person [1.07]\n",
      "total detections :  1\n",
      "[[53, 70, 600]]\n",
      "1/1 [==============================] - 0s 441ms/step\n",
      "front person [1.07]\n",
      "total detections :  1\n",
      "[[60, 81, 600]]\n"
     ]
    }
   ],
   "source": [
    "import os     \n",
    "import cv2    \n",
    "video = cv2.VideoCapture(0)\n",
    "# video = cv2.VideoCapture('sample.mp4')    \n",
    "count = 0 \n",
    "while True:    \n",
    "    ret , frame = video.read()\n",
    "    if ret == True:  \n",
    "        count += 1 \n",
    "        if count % 48 == 0:  \n",
    "            name = 'frame {} in {} sec.png'.format((count//5),count//32) \n",
    "            cv2.imwrite(name,frame)\n",
    "            image_detection(name)  \n",
    "#             p1 = Thread(target = image_detection , agrs = (name,) )\n",
    "#             p1.start() \n",
    "    \n",
    "            os.remove(name) \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "video.release()  \n",
    "cv2.destroyAllWindows()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "348e79ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_detection('people.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "c1b0a74d71e5798ef68d64ed441403c23ef7b532a1f7034c4c1f4c0b8e8b4d38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
